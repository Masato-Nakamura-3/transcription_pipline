{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c841780",
   "metadata": {},
   "source": [
    "## What this script does:\n",
    "\n",
    "1. Extract candidate words a dictionary file (handled with keywords.ipynb)\n",
    "2. Run Google Cloud Speech-to-Text to get transcription of wav files, which is constrained by existing human(-corrected) transcriptions\n",
    "3. Output a dictionary file that maps filenames onto transcriptions\n",
    "4. Combine the transcription, onset, and context info to generate TextGrid files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e8745",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3422946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import textgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f5661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input directory\n",
    "wav_dir = \"/Users/masato/Box/cloze_experiments/filter/batch2/wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc24201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of wav files\n",
    "filenames = [i for i in os.listdir(wav_dir) if (\".wav\" in i and \"exp\" in i)]\n",
    "bnames = [os.path.splitext(f)[0] for f in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182082c4",
   "metadata": {},
   "source": [
    "## Get candidate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92aaed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest file from /automatic_transcription/keywords/ directory\n",
    "keyword_list = pickle.load( open( \"/Users/masato/Box/cloze_experiments/automatic_transcription/keywords/keywords_1110.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703602e",
   "metadata": {},
   "source": [
    "## Google Cloud Speech-to-Text\n",
    "\n",
    "You can skip this part if you are not using this api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652d301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the appropriate path to the API key\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/masato/Documents/Research/transcription/googlecloud/autotranscription-test-e12d3589a265.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that maps a file name onto a transcription for later use\n",
    "dict_gcloud = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to save the file names of items that the transcriber wasn't able to recognize\n",
    "failed_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb37f8",
   "metadata": {},
   "source": [
    "Based on a snippet from:\n",
    "https://cloud.google.com/speech-to-text/docs/sync-recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f00d5e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# google cloud api\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "for file in filenames:\n",
    "    transc_list = []\n",
    "    \n",
    "    # Load the audio file\n",
    "    filepath = os.path.join(wav_dir, file)\n",
    "    with io.open(filepath, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    \n",
    "    # Load the key words\n",
    "    item_id = int(os.path.splitext(file)[0].split(\"_\")[1][:-1])\n",
    "    speech_context = speech.SpeechContext(phrases=keyword_list[item_id])\n",
    "    \n",
    "\n",
    "    # Transcription by Google Cloud Speech-to-Text\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        language_code=\"en-US\",\n",
    "        speech_contexts=[speech_context],\n",
    "    )\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for result in response.results:\n",
    "            transc_list.append(result.alternatives[0].transcript)\n",
    "        transc = \" \".join(transc_list)\n",
    "        \n",
    "        # If the transcription is empty\n",
    "        if len(transc) == 0:\n",
    "            transc = \"NOT_RECOGNIZED\"\n",
    "            failed_list.append(file)\n",
    "            \n",
    "        print(file+\":\\t\" + transc)\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        print(\"Error at \", file)\n",
    "        failed_list.append(file)\n",
    "        transc = \"FAILED \"\n",
    "        \n",
    "    dict_gcloud[os.path.splitext(file)[0]] = transc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834864b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e77dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch exceptionally short ones which might cause errors later\n",
    "short = [(f, dict_gcloud[f]) for f in dict_gcloud.keys() if len(dict_gcloud[f]) < 2]\n",
    "print(short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dict_gcloud, open( \"\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d4119",
   "metadata": {},
   "source": [
    "# Outputting files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16519cd",
   "metadata": {},
   "source": [
    "## Output functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7a14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates .TextGrid files for Praat\n",
    "# You can optionally give it a dictionary for the onset and/or for the duration of the files\n",
    "# The onset function is basically for Chronset\n",
    "# You can also give it context info\n",
    "\n",
    "# This now works with inconsistent durations\n",
    "# In that case set add an argument of \"inconsistent = 1\"\n",
    "\n",
    "# The function replaces the RT with 0.1 if the RT is 0 or shorter, or is NaN, producing an error message\n",
    "def generate_textgrid(dictionary, output_dir, template, onset = dict(), context = dict(), inconsistent = 0):\n",
    "    import copy\n",
    "    \n",
    "    for k in dictionary.keys():\n",
    "        \n",
    "        try:\n",
    "            # Load the TextGrid template and edit it\n",
    "            tg = copy.deepcopy(template)\n",
    "            \n",
    "            # If the duration of the audio files are inconsistent, edit each TextGrid files to match the duration of the audio files\n",
    "            if inconsistent == 1:                     \n",
    "                audio = AudioSegment.from_file(os.path.join(wav_dir, k + \".wav\"))\n",
    "                tg[\"words\"][1].xmax = tg[\"words\"][-1].xmin = audio.duration_seconds - 0.001\n",
    "                \n",
    "                if tg.xmax != audio.duration_seconds:\n",
    "                    tg.xmax = audio.duration_seconds\n",
    "\n",
    "                    for tier in tg.keys():\n",
    "                        tg[tier][-1].xmax = audio.duration_seconds\n",
    "            \n",
    "            \n",
    "            tg[\"words\"][1].text = dictionary[k]\n",
    "\n",
    "            if k in onset.keys():\n",
    "                # If the onset is not detected or is negative, set 0.1\n",
    "                if np.isnan(onset[k]) or onset[k] <= 0 :\n",
    "                    print(\"No onset for \", k)\n",
    "                    tg[\"words\"][0].xmax = tg[\"words\"][1].xmin = 0.1\n",
    "                else:\n",
    "                    tg[\"words\"][0].xmax = tg[\"words\"][1].xmin = onset[k]\n",
    "\n",
    "            item_num = int(k.split(\"_\")[1][:-1])\n",
    "\n",
    "            if item_num in context.keys():\n",
    "                tg[\"context\"][0].text = context[item_num]\n",
    "\n",
    "            tg.write(os.path.join(output_dir, k + \".TextGrid\"))\n",
    "            \n",
    "        except:\n",
    "            print(\"Error at \", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duration of an audio file and edit the template\n",
    "instance = AudioSegment.from_file(os.path.join(wav_dir, filenames[0]))\n",
    "template[\"words\"][1].xmax = template[\"words\"][-1].xmin = instance.duration_seconds - 0.001\n",
    "\n",
    "# Make sure the duration of the audio files matches the template\n",
    "\n",
    "if template.xmax != instance.duration_seconds:\n",
    "    template.xmax = instance.duration_seconds\n",
    "    \n",
    "    for k in template.keys():\n",
    "        template[k][-1].xmax = instance.duration_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4c445",
   "metadata": {},
   "source": [
    "## Setting up for outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cde55a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need this line if you are not using Google Cloud Speech-to-Text\n",
    "output_dir_c = \"/Users/masato/Box/cloze_experiments/filter/batch2/tg_raw_new\" \n",
    "dict_gcloud = pickle.load( open( \"/Users/masato/Box/cloze_experiments/filter/batch2/gcloud.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb3798",
   "metadata": {},
   "source": [
    "## Generate .textgrid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cac7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a template\n",
    "template = textgrids.TextGrid(\"/Users/masato/Box/cloze_experiments/automatic_transcription/temp_note.TextGrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0bc37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File type = \"ooTextFile\"\n",
       "Object class = \"TextGrid\"\n",
       "\n",
       "xmin = 0.0\n",
       "xmax = 3.36\n",
       "tiers? <exists>\n",
       "size = 3\n",
       "item []:\n",
       "    item [1]:\n",
       "        class = \"IntervalTier\"\n",
       "        name = \"words\"\n",
       "        xmin = 0.0\n",
       "        xmax = 3.36\n",
       "        intervals: size = 3\n",
       "            intervals [1]:\n",
       "                xmin = 0.0\n",
       "                xmax = 0.5695189325640101\n",
       "                text = \"\"\n",
       "            intervals [2]:\n",
       "                xmin = 0.5695189325640101\n",
       "                xmax = 2.9325394879192213\n",
       "                text = \"==TRANSCRIPTION==\"\n",
       "            intervals [3]:\n",
       "                xmin = 2.9325394879192213\n",
       "                xmax = 3.36\n",
       "                text = \"\"\n",
       "    item [1]:\n",
       "        class = \"IntervalTier\"\n",
       "        name = \"context\"\n",
       "        xmin = 0.0\n",
       "        xmax = 3.36\n",
       "        intervals: size = 1\n",
       "            intervals [1]:\n",
       "                xmin = 0.0\n",
       "                xmax = 3.36\n",
       "                text = \"\"\n",
       "    item [1]:\n",
       "        class = \"IntervalTier\"\n",
       "        name = \"notes\"\n",
       "        xmin = 0.0\n",
       "        xmax = 3.36\n",
       "        intervals: size = 1\n",
       "            intervals [1]:\n",
       "                xmin = 0.0\n",
       "                xmax = 3.36\n",
       "                text = \"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c469ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duration of an audio file and edit the template\n",
    "instance = AudioSegment.from_file(os.path.join(wav_dir, filenames[0]))\n",
    "template[\"words\"][1].xmax = template[\"words\"][-1].xmin = instance.duration_seconds - 0.001\n",
    "\n",
    "# Make sure the duration of the audio files matches the template\n",
    "\n",
    "if template.xmax != instance.duration_seconds:\n",
    "    template.xmax = instance.duration_seconds\n",
    "    \n",
    "    for k in template.keys():\n",
    "        template[k][-1].xmax = instance.duration_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59589071",
   "metadata": {},
   "source": [
    "### Get onset data from Chronset (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c5e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cfc279",
   "metadata": {},
   "source": [
    "#### Read the output of Chronset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98a4a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with Chronset output files\n",
    "ch_dir = \"/Users/masato/Box/cloze_experiments/filter/batch2/chronset/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64273539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load the output of Chronset\n",
    "# Create a dictionary that maps the file names onto onset time (sec)\n",
    "# Note that chronset uses miliseconds while praat uses seconds\n",
    "for textf in [t for t in os.listdir(ch_dir) if \".txt\" in t]:\n",
    "    onset_df = pd.read_table(os.path.join(ch_dir, textf), names = [\"wav\", \"rt\"])\n",
    "    temp_dict = dict(zip([os.path.splitext(w)[0] for w in onset_df[\"wav\"]], onset_df[\"rt\"] / 1000))\n",
    "    onset_dict.update(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7aa3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary with context information\n",
    "cont_dict = pickle.load( open( \"/Users/masato/Box/cloze_experiments/automatic_transcription/data/context.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "403d9c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No onset for  exp_10a_fobi\n",
      "No onset for  exp_11a_pqpc\n",
      "No onset for  exp_11a_yafl\n",
      "No onset for  exp_12b_jpej\n",
      "No onset for  exp_12b_pqpc\n",
      "No onset for  exp_13a_ewki\n",
      "No onset for  exp_13a_jpej\n",
      "No onset for  exp_13b_hspi\n",
      "No onset for  exp_13b_rmht\n",
      "No onset for  exp_13b_ydyq\n",
      "No onset for  exp_14a_ydyq\n",
      "No onset for  exp_14a_zscx\n",
      "No onset for  exp_14b_jpej\n",
      "No onset for  exp_14b_pqpc\n",
      "No onset for  exp_15a_jbjb\n",
      "No onset for  exp_15a_qpmx\n",
      "No onset for  exp_15a_xiih\n",
      "No onset for  exp_15b_ldan\n",
      "No onset for  exp_16b_jbjb\n",
      "No onset for  exp_16b_pqpc\n",
      "No onset for  exp_17a_bcof\n",
      "No onset for  exp_18a_zscx\n",
      "No onset for  exp_18b_kxnd\n",
      "No onset for  exp_1a_jbjb\n",
      "No onset for  exp_1b_fobi\n",
      "No onset for  exp_20b_jpej\n",
      "No onset for  exp_21a_jpej\n",
      "No onset for  exp_21b_hspi\n",
      "No onset for  exp_22a_rvun\n",
      "No onset for  exp_23a_pnuh\n",
      "No onset for  exp_23a_qpmx\n",
      "No onset for  exp_23b_ynpp\n",
      "No onset for  exp_24b_pnuh\n",
      "No onset for  exp_25b_ydyq\n",
      "No onset for  exp_26a_lopr\n",
      "No onset for  exp_26b_jpej\n",
      "No onset for  exp_26b_mage\n",
      "No onset for  exp_27a_pnuh\n",
      "No onset for  exp_27a_xiih\n",
      "No onset for  exp_29a_ewki\n",
      "No onset for  exp_29a_fwqr\n",
      "No onset for  exp_29a_pqpc\n",
      "No onset for  exp_29b_bxxd\n",
      "No onset for  exp_29b_qygq\n",
      "No onset for  exp_2a_ckjd\n",
      "No onset for  exp_30a_hkbq\n",
      "No onset for  exp_30b_yjcx\n",
      "No onset for  exp_31a_bcof\n",
      "No onset for  exp_32a_tnao\n",
      "No onset for  exp_32b_fwqr\n",
      "No onset for  exp_32b_ilfd\n",
      "No onset for  exp_33b_hspi\n",
      "No onset for  exp_35a_jpej\n",
      "No onset for  exp_35a_kxnd\n",
      "No onset for  exp_35b_zscx\n",
      "No onset for  exp_36a_hkbq\n",
      "No onset for  exp_37a_jpej\n",
      "No onset for  exp_37b_bxxd\n",
      "No onset for  exp_37b_ydyq\n",
      "No onset for  exp_37b_zscx\n",
      "No onset for  exp_38b_pqpc\n",
      "No onset for  exp_38b_yafl\n",
      "No onset for  exp_39a_fwqr\n",
      "No onset for  exp_39a_rhdv\n",
      "No onset for  exp_39b_cnis\n",
      "No onset for  exp_40a_ydyq\n",
      "No onset for  exp_40b_mage\n",
      "No onset for  exp_42a_fobi\n",
      "No onset for  exp_42b_rkxm\n",
      "No onset for  exp_43a_jbjb\n",
      "No onset for  exp_43a_jpej\n",
      "No onset for  exp_43a_yafl\n",
      "No onset for  exp_43b_fobi\n",
      "No onset for  exp_43b_ydyq\n",
      "No onset for  exp_44a_cnis\n",
      "No onset for  exp_44b_jpej\n",
      "No onset for  exp_45b_fobi\n",
      "No onset for  exp_45b_qjyq\n",
      "No onset for  exp_46b_ahcw\n",
      "No onset for  exp_46b_kxnd\n",
      "No onset for  exp_47a_qpmx\n",
      "No onset for  exp_47b_qygq\n",
      "No onset for  exp_48b_rkxm\n",
      "No onset for  exp_49b_ydyq\n",
      "No onset for  exp_4b_yafl\n",
      "No onset for  exp_52a_ynpp\n",
      "No onset for  exp_53a_yjcx\n",
      "No onset for  exp_53b_ydyq\n",
      "No onset for  exp_54a_hspi\n",
      "No onset for  exp_54a_ldan\n",
      "No onset for  exp_54a_ydyq\n",
      "No onset for  exp_54b_jbjb\n",
      "No onset for  exp_54b_jpej\n",
      "No onset for  exp_56a_qvem\n",
      "No onset for  exp_57a_jbjb\n",
      "No onset for  exp_58a_fobi\n",
      "No onset for  exp_58b_jpej\n",
      "No onset for  exp_5a_jpej\n",
      "No onset for  exp_5b_tnao\n",
      "No onset for  exp_5b_xsty\n",
      "No onset for  exp_60a_qjyq\n",
      "No onset for  exp_60a_qygq\n",
      "No onset for  exp_60b_bcof\n",
      "No onset for  exp_60b_fwqr\n",
      "No onset for  exp_6a_hkbq\n",
      "No onset for  exp_7a_pqpc\n",
      "No onset for  exp_7b_rvun\n",
      "No onset for  exp_8a_ldan\n",
      "No onset for  exp_8b_rhdv\n",
      "No onset for  exp_9a_pnuh\n",
      "No onset for  exp_9b_cnis\n",
      "No onset for  exp_9b_hkbq\n"
     ]
    }
   ],
   "source": [
    "# Generate textgrids with Google Cloud transcription\n",
    "# Omit the last argument if you don't use the onset info\n",
    "# set inconsistent = 1 if the durations of audio files are inconsistent\n",
    "\n",
    "generate_textgrid(dict_gcloud, output_dir_c, template, onset = onset_dict, context = cont_dict) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8717fef2",
   "metadata": {},
   "source": [
    "**Recommended**  \n",
    "Run common_errors.ipynb after this to correct some common issues regarding homophones/inflections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
