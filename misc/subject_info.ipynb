{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script maps the PC Ibex result files (one for each list) onto a table with subject information.\n",
    "Mostly for approving / rejecting HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- subject_id used for filenames (4 alphabets)\n",
    "- the name of zip files\n",
    "- Unique Identifiers (8 alphabets/numbers)\n",
    "- Worker ID/Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The names of the result csv files must end with the list id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result directory\n",
    "# The last character/number must indicate the name of the latin-square list\n",
    "result_dir = \"\"\n",
    "\n",
    "# Set the output path\n",
    "output_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path of the result files\n",
    "file_list = [f for f in os.listdir(result_dir) if \"results\" in f]\n",
    "path_list = [os.path.join(result_dir, f) for f in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the relevant raws for all the lists / experiments\n",
    "\n",
    "idt_list_all = [] # identifier\n",
    "wid_list_all = [] # worker id\n",
    "fn_list_all = [] # zipfile names\n",
    "ls_list = [] # list id\n",
    "subjid_list_all = [] #subject id\n",
    "\n",
    "for p in path_list:\n",
    "    with open(p) as f:\n",
    "        raw = f.readlines()\n",
    "    list_id = os.path.splitext(os.path.basename(p))[0][-1]\n",
    "    rel1 = [i for i in raw if \"exit_form\" in i or \"DYNAMIC\" in i]\n",
    "    # Get the relevant raws\n",
    "    idt_list_raw = [r.split(\",\") for r in [i for i in rel1 if \"identifier\" in i]]\n",
    "    idt_list_all = idt_list_all + idt_list_raw\n",
    "    \n",
    "    wid_list_raw = [r.split(\",\") for r in [i for i in rel1 if \"worker_id\" in i]]\n",
    "    wid_list_all = wid_list_all + wid_list_raw\n",
    "    \n",
    "    fn_list_raw = [r.split(\",\") for r in [i for i in rel1 if \"Filename\" in i]]\n",
    "    fn_list_all = fn_list_all + fn_list_raw\n",
    "    \n",
    "    ls_list = ls_list + [list_id] * len(fn_list_raw)\n",
    "        \n",
    "    subjid_list_raw = [r.split(\",\") for r in [l for l in raw if \"exp_60\" in l]]\n",
    "    subjid_list_all = subjid_list_all + subjid_list_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the time and the ip address is lined up\n",
    "time_list = [idt_list_all[i][0] for i in range(0, len(idt_list_all))]\n",
    "time_list1 = [wid_list_all[i][0] for i in range(0, len(wid_list_all))]\n",
    "time_list2 = [fn_list_all[i][0] for i in range(0, len(fn_list_all))]\n",
    "\n",
    "ip_list = [idt_list_all[i][1] for i in range(0, len(idt_list_all))]\n",
    "ip_list1 = [wid_list_all[i][1] for i in range(0, len(wid_list_all))]\n",
    "ip_list2 = [fn_list_all[i][1] for i in range(0, len(fn_list_all))]\n",
    "\n",
    "print(time_list == time_list1 and time_list == time_list2)\n",
    "print(ip_list == ip_list1 and ip_list == ip_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert times as strings to times as integers\n",
    "time_list_i = [int(i) for i in time_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the info\n",
    "idt_list = [idt_list_all[i][9] for i in range(0, len(idt_list_all))]\n",
    "wid_list = [wid_list_all[i][9] for i in range(0, len(wid_list_all))]\n",
    "fn_list = [fn_list_all[i][9] for i in range(0, len(fn_list_all))]\n",
    "\n",
    "subjid_list = [subjid_list_all[i][11] for i in range(0, len(subjid_list_all))]\n",
    "subjid_list_c = [subjid_list_all[i][7].split(\"_\")[-1] for i in range(0, len(subjid_list_all))]\n",
    "\n",
    "subjid_list == subjid_list_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table for all the info\n",
    "subj_table = pd.DataFrame({\"time\": time_list_i, \"ip\": ip_list, \"identifier\":idt_list, \"worker_id\": wid_list, \"subject_id\":subjid_list, \"filename\": fn_list, \"list\": ls_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if there are multiple submissions from the same IP address\n",
    "if len(set(subj_table.ip)) != len(subj_table):\n",
    "    import collections\n",
    "    print(collections.Counter(subj_table.ip).most_common())\n",
    "\n",
    "else:\n",
    "    print(\"No multiple submissions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the result into a csv file\n",
    "#subj_table.to_csv(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add batch info based on the reception time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [1634850000, 1636000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_table[\"batch\"] = \"batch2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_table.loc[subj_table[\"time\"] < boundaries[0], [\"batch\"]] = \"pilot\"\n",
    "subj_table.loc[(subj_table[\"time\"] > boundaries[0]) & (subj_table[\"time\"] < boundaries[1]), [\"batch\"]] = \"batch1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the result into a csv file\n",
    "subj_table.to_csv(output_path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MTurk result files to add batch information and check submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_res_dir = \"\"\n",
    "id_string = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_res_p = [os.path.join(amt_res_dir, fn) for fn in os.listdir(amt_res_dir) if id_string in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcolnames = ['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'Reward',\n",
    "       'CreationTime', 'MaxAssignments', 'RequesterAnnotation',\n",
    "       'AssignmentDurationInSeconds', 'AutoApprovalDelayInSeconds',\n",
    "       'Expiration', 'NumberOfSimilarHITs', 'LifetimeInSeconds',\n",
    "       'AssignmentId', 'WorkerId', 'AssignmentStatus', 'AcceptTime',\n",
    "       'SubmitTime', 'AutoApprovalTime', 'ApprovalTime', 'RejectionTime',\n",
    "       'RequesterFeedback', 'WorkTimeInSeconds', 'LifetimeApprovalRate',\n",
    "       'Last30DaysApprovalRate', 'Last7DaysApprovalRate', 'Input.url',\n",
    "       'Answer.Code', 'Answer.FileName', 'Answer.Identifier', 'Answer.Name',\n",
    "       'Approve', 'Reject', 'UPDATE-Already participated (WYCL)'] + [\"BatchId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_result = None\n",
    "for p in amt_res_p:\n",
    "    t_amt_result = pd.read_csv(p)\n",
    "    batchid = os.path.splitext(p)[0].split(\"_\")[-1]\n",
    "    t_amt_result[\"BatchId\"] = batchid\n",
    "    \n",
    "    if \"amt_result\" in locals():\n",
    "        amt_result = pd.concat([amt_result, t_amt_result])\n",
    "    else:\n",
    "        amt_result = t_amt_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amtset = set(amt_result[\"WorkerId\"])\n",
    "pcibexset = set(subj_table[\"worker_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_pcibex = amtset - pcibexset\n",
    "not_in_amt = pcibexset - amtset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_pcibex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subj_table[subj_table[\"worker_id\"].isin(not_in_amt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amt_result[amt_result[\"WorkerId\"].isin(not_in_pcibex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = subj_table[subj_table[\"batch\"] == \"batch2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist = []\n",
    "for w in subj_table.worker_id:\n",
    "    \n",
    "    if np.sum(amt_result[\"WorkerId\"] == w) == 0:\n",
    "        checklist.append(w)\n",
    "    else:\n",
    "        amt_id = amt_result[amt_result[\"WorkerId\"] == w][\"Answer.Identifier\"].iloc[0]\n",
    "        pc_id = subj_table[subj_table[\"worker_id\"] == w][\"identifier\"].iloc[0]\n",
    "    \n",
    "        if amt_id != pc_id:\n",
    "            checklist.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_table[subj_table[\"worker_id\"].isin(checklist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_result[amt_result[\"WorkerId\"].isin(checklist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
